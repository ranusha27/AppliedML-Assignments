{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4f323d",
   "metadata": {},
   "source": [
    "# Applied Machine Learning - Assignment 2\n",
    "##### Submitted by \n",
    "- Anusha R\n",
    "- MDS202212\n",
    "- anushar@cmi.ac.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3e8efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beb25606",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e21a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8f3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from a given file path\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a404204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text_cleaned = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text_cleaned\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['text'] = df['text'].apply(lambda x: preprocess_text(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "202ce627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train/validation/test \n",
    "\n",
    "def split_data(df, test_size=0.2, validation_size=0.25, random_state=42):\n",
    "    train, test = train_test_split(df, test_size=test_size, \n",
    "                                   random_state=random_state)\n",
    "    \n",
    "    train, validation = train_test_split(train, test_size=validation_size, \n",
    "                                         random_state=random_state)\n",
    "    \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9ef008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the splits at train.csv/validation.csv/test.csv\n",
    "\n",
    "def save_data(train, validation, test, train_path='train.csv', validation_path='validation.csv', test_path='test.csv'):\n",
    "    train.to_csv(train_path, index=False)\n",
    "    validation.to_csv(validation_path, index=False)\n",
    "    test.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbbf99",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff3f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "file_path = os.path.join(current_directory, 'Dataset/emails.csv')\n",
    "data = load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8728f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_data(data) # Preprocess the data\n",
    "\n",
    "train_data, validation_data, test_data = split_data(preprocessed_data) # Split the data as train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf2b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_data, validation_data, test_data) # Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9758dc",
   "metadata": {},
   "source": [
    "## Implementing GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4807fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "Initialized empty Git repository in D:/CMI DS/Sem 4/AML/Assignment2/.git/\n"
     ]
    }
   ],
   "source": [
    "!dvc init --no-scm --f\n",
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f496b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Dataset/emails.csv', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "# Track data files with DVC\n",
    "\n",
    "!git add \"D:\\CMI DS\\Sem 4\\AML\\Assignment2\\Dataset\\emails.csv\" train.csv validation.csv test.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f7bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) c3b587f] Added raw data, train, test and validation data after splitting\n",
      " 4 files changed, 11460 insertions(+)\n",
      " create mode 100644 Dataset/emails.csv\n",
      " create mode 100644 test.csv\n",
      " create mode 100644 train.csv\n",
      " create mode 100644 validation.csv\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Added raw data, train, test and validation data after splitting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57aa1dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.dvc/\n",
      "\t.dvcignore\n",
      "\t.ipynb_checkpoints/\n",
      "\tprepare.ipynb\n",
      "\ttrain.ipynb\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828c93c",
   "metadata": {},
   "source": [
    "## Split the data again with different random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8d4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = split_data(preprocessed_data, random_state=1) # Split the data as train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88fcc0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_data, validation_data, test_data) # Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e2f7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   test.csv\n",
      "\tmodified:   train.csv\n",
      "\tmodified:   validation.csv\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.dvc/\n",
      "\t.dvcignore\n",
      "\t.ipynb_checkpoints/\n",
      "\tprepare.ipynb\n",
      "\ttrain.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6054c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add \"D:\\CMI DS\\Sem 4\\AML\\Assignment2\\Dataset\\emails.csv\" train.csv validation.csv test.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "114deb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master fe49dbf] Updated dataset for random state 1\n",
      " 3 files changed, 5596 insertions(+), 5596 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Updated dataset for random state 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d52e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe49dbf Updated dataset for random state 1\n",
      "c3b587f Added raw data, train, test and validation data after splitting\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c535e",
   "metadata": {},
   "source": [
    "## Distribution of target variable for initial split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe038fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD is now at c3b587f Added raw data, train, test and validation data after splitting\n"
     ]
    }
   ],
   "source": [
    "!git checkout c3b587f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14d58482",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a34e54fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+------+\n",
      "| Dataset         |   0s |   1s |\n",
      "+=================+======+======+\n",
      "| Training data   | 2616 |  820 |\n",
      "+-----------------+------+------+\n",
      "| Validation data |  872 |  274 |\n",
      "+-----------------+------+------+\n",
      "| Test data       |  872 |  274 |\n",
      "+-----------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"Training data\", sum(train_data['spam'] == 0), sum(train_data['spam'] == 1)],\n",
    "    [\"Validation data\", sum(validation_data['spam'] == 0), sum(validation_data['spam'] == 1)],\n",
    "    [\"Test data\", sum(test_data['spam'] == 0), sum(test_data['spam'] == 1)]\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=[\"Dataset\", \"0s\", \"1s\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdd67037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was c3b587f Added raw data, train, test and validation data after splitting\n",
      "HEAD is now at fe49dbf Updated dataset for random state 1\n"
     ]
    }
   ],
   "source": [
    "!git checkout fe49dbf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7728a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "546dd112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+------+\n",
      "| Dataset         |   0s |   1s |\n",
      "+=================+======+======+\n",
      "| Training data   | 2624 |  812 |\n",
      "+-----------------+------+------+\n",
      "| Validation data |  860 |  286 |\n",
      "+-----------------+------+------+\n",
      "| Test data       |  876 |  270 |\n",
      "+-----------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"Training data\", sum(train_data['spam'] == 0), sum(train_data['spam'] == 1)],\n",
    "    [\"Validation data\", sum(validation_data['spam'] == 0), sum(validation_data['spam'] == 1)],\n",
    "    [\"Test data\", sum(test_data['spam'] == 0), sum(test_data['spam'] == 1)]\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=[\"Dataset\", \"0s\", \"1s\"], tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
